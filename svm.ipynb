{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import sklearn \n",
    "from numpy import asarray\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'transformed_zoom500_dim130x100/data/'\n",
    "highRMFolder = folder + 'HighRm/'\n",
    "lowRMFolder = folder + 'LowRm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = glob.glob(lowRMFolder + '*.png')\n",
    "high = glob.glob(highRMFolder + '*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset size, we have much more low rm samples than high_rm samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11356\n",
      "1511\n"
     ]
    }
   ],
   "source": [
    "low_samples_cnt = len(low)\n",
    "high_samples_cnt = len(high)\n",
    "print(low_samples_cnt)\n",
    "print(high_samples_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare subset of data with same size of both classes to train our model and to test it, if run on machine with enough resources this can be modified up to min(low_samples_cnt, high_samples_cnt) or even all data can be loaded, but we separate it on the level of loading image since this operation is resource extensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 200\n",
    "test_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = random.sample(low, train_size) + random.sample(high, train_size)\n",
    "test_images = random.sample(low, test_size) + random.sample(high, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([asarray(Image.open(im)).ravel() for im in train_images])\n",
    "X_test = np.array([asarray(Image.open(im)).ravel() for im in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 for _ in range(train_size)] +  [1 for _ in range(train_size)]\n",
    "y_test = [0 for _ in range(test_size)] +  [1 for _ in range(test_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(SVC(gamma='auto'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with scalling\n",
    "\n",
    "scaling improved the result to nearly 90 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699999999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moments\n",
    "\n",
    "moments of image did not introduce any progress\n",
    "https://en.wikipedia.org/wiki/Image_moment\n",
    "\n",
    "for most of randomly chosen sample of training set it were giving worse performance, but sometimes it have higher score on cross validation score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.measure\n",
    "\n",
    "\n",
    "X = np.array([skimage.measure.moments(skimage.io.imread(im)).ravel() for im in train_images])\n",
    "X_test = np.array([skimage.measure.moments(skimage.io.imread(im)).ravel() for im in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 for _ in range(train_size)] +  [1 for _ in range(train_size)]\n",
    "y_test = [0 for _ in range(test_size)] +  [1 for _ in range(test_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hu moments \n",
    "https://medium.com/@dataturks/understanding-svms-for-image-classification-cf4f01232700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "X = np.array([skimage.measure.moments_hu(rgb2gray(skimage.io.imread(im))).ravel() for im in train_images])\n",
    "X_test = np.array([skimage.measure.moments_hu(rgb2gray(skimage.io.imread(im))).ravel() for im in test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 for _ in range(train_size)] +  [1 for _ in range(train_size)]\n",
    "y_test = [0 for _ in range(test_size)] +  [1 for _ in range(test_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(SVC(gamma='auto'))\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8225"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# further tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after trying above methods simple svc with scaling, resulted in best score (sometimes simple moments were better), that is why we have focused on improving its results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel is: linear\n",
      "mean score: 0.8200000000000001\n",
      "kernel is: poly\n",
      "mean score: 0.7449999999999999\n",
      "kernel is: rbf\n",
      "mean score: 0.8699999999999999\n",
      "kernel is: sigmoid\n",
      "mean score: 0.8724999999999999\n"
     ]
    }
   ],
   "source": [
    "X = np.array([asarray(Image.open(im)).ravel() for im in train_images])\n",
    "X_test = np.array([asarray(Image.open(im)).ravel() for im in test_images])\n",
    "\n",
    "y = [0 for _ in range(train_size)] +  [1 for _ in range(train_size)]\n",
    "y_test = [0 for _ in range(test_size)] +  [1 for _ in range(test_size)]\n",
    "\n",
    "for k in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto', kernel = k))\n",
    "    clf.fit(X, y)\n",
    "    print('kernel is: ' + k )\n",
    "    print('mean score: ' + str(np.mean(cross_val_score(clf, X, y, cv=10))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699999999999999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', probability=True))\n",
    "clf.fit(X, y)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699999999999999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', cache_size=1000))\n",
    "clf.fit(X, y)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699999999999999"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', decision_function_shape='ovo'))\n",
    "clf.fit(X, y)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying full dataset for moments (faster computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9273324222002295"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([skimage.measure.moments(skimage.io.imread(im)).ravel() for im in low + high])\n",
    "y = y = [0 for _ in range(low_samples_cnt)] +  [1 for _ in range(high_samples_cnt)]\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X, y)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final conclusion\n",
    "\n",
    "SVC + StandardScalerwork great on data processed by our data manipulator, but for some random inputs it resulted in worse score than using moments of image\n",
    "\n",
    "SVC work best with defualt rbf kernel but sometimes sigmoid returned a bit better result\n",
    "\n",
    "Trying moment and hu moment resulted in simmillar score but it get a lot better if it comes to processing time, that is why even on slow pcs it is easy to rpocess whole dataset which was the best score among all tries.\n",
    "\n",
    "final result ~93%  on cross val score with 10-fold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
